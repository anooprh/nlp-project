\documentclass[dvips,12pt]{article}

% Any percent sign marks a comment to the end of the line

% Every latex document starts with a documentclass declaration like this
% The option dvips allows for graphics, 12pt is the font size, and article
%   is the style

\usepackage[pdftex]{graphicx}
\usepackage{url}

% These are additional packages for "pdflatex", graphics, and to include
% hyperlinks inside a document.

\setlength{\oddsidemargin}{0.25in}
\setlength{\textwidth}{6.5in}
\setlength{\topmargin}{0in}
\setlength{\textheight}{8.5in}

% These force using more of the margins that is the default style

\begin{document}
	
	% Everything after this becomes content
	% Replace the text between curly brackets with your own
	
	\title{Keyword extraction by deep learning}
	\author{Yi Cheng(andrewId), Anoop Hallur(ahallur), Xiaoqiu Huang(andrewId)}
	\date{\today}
	
	% You can leave out "date" and it will be added automatically for today
	% You can change the "\today" date to any text you like
	
	\maketitle
	
	% This command causes the title to be created in the document
	
	\section{Introduction}
		In this project, we plan to implement keyword extraction of short and long textual data by application of deep learning. We would like it learn the highest ranked words in it by constructing a suitable models of the words in the document.

	\section{Dataset}
		We have identified data from stackexchange( \url{https://archive.org/download/stackexchange/stackexchange_archive.torrent}) to be a suitable data set for our project. It has labelled data from various topics such as programming, travel, philosophy etc. We have apporximately 20 GB of labelled data. This is large data set to test our algorithms on a larger scale. For our project we plan to train on a specified portion of the data and test on the remaining data. Since the data is cleanly labelled, we need not do any special processing/cleaning up of the data set other than splitting it into smaller segements for it to be suitable to work on.
	
	% An article style is separated into sections and subsections with 
	%   markup such as this.  Use \section*{Principles} for unnumbered sections.
	\section{Plan and Milestone}
	Since in this project, we try to apply \emph{Deep Learning to Keyword Extraction}, we divide the project into the following small tasks:
	\begin{enumerate}
		\item Be familiar with existing techniques and related works.
		\item Learn \emph{Deep Learning} method and how it can be used in NLP related applications.
		\item Design our model and  experiment with the parameters and try to improve the model.
		\item Analyze the performance on the test data set and summarize the results in the project report.
	\end{enumerate}
	For the midterm report, we aim to finish the first two tasks, i.e implement some of the previously proposed methods and test them on the stackexchange dataset.
	\section{Goal}
	We need to apply \emph{Deep Learning} to the problem and do experiments on it. If the performance is worse than that of the previous works, \textbf{at least} we need to figure the reason as to why the performance is poor and how to improve it. \\
	As a stretch goal, we need to improve the model itself and try to do keywords generation (//i did not understand what you mean here//) and finally convert it to a model suitable for unsupervised tasks.
	\begin{thebibliography}{99}
		
		\bibitem{socher2013} Richard Socher, 
		Alex Perelygin,	
		Jean Y. Wu,	
		Jason Chuang,	
		Christopher D. Manning,	
		Andrew Y. Ng	
		and  Christopher Potts,
		{Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank},
		EMNLP, (2013).

		\bibitem{socher2011} Richard Socher, 
		Cliï¬€ Chiung-Yu Lin,		
		Christopher D. Manning,	
		and Andrew Y. Ng	
		{Parsing Natural Scenes and Natural Language with Recursive Neural Networks},
		NIPS, (2011).
				
	\end{thebibliography}
	
	
	
\end{document}